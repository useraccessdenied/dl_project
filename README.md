# B-FQG: Bloom's Taxonomy-based Follow-up Question Generation

Implementation of the ACL 2025 Industry Track paper: **"From Recall to Creation: Generating Follow-Up Questions Using Bloom's Taxonomy and Grice's Maxims"**

This project implements a framework for generating cognitively scaffolded follow-up questions using Bloom's Taxonomy and evaluating them with Gricean-inspired metrics.

## Overview

The system uses Large Language Models to generate follow-up questions that progressively increase in cognitive complexity from basic recall (Level 1) to advanced creation (Level 6) according to Bloom's Revised Taxonomy. Generated questions are evaluated using the GriceWise framework based on conversational principles.

### Key Components
- **B-FQG Generator**: Creates 5 follow-up questions per seed question across cognitive levels (Understand to Create). Uses a focused, independent generation strategy for each level to ensure high quality.
- **GriceWise Evaluator**: Assesses questions using Gricean Maxims (Quality, Quantity, Relation, Manner).
- **Recursive Pipeline**: Iteratively refines questions by clustering them into high/low quality groups and using the high-quality examples to prompt-tune the model for subsequent iterations.

## Installation

```bash
# Clone the repository and navigate to it
cd /path/to/dl_project

# Install dependencies using uv
uv sync

# Run setup to download models and resources
uv run python pre_run.py
```

## Usage

### Batch Processing (Recursive Pipeline)
```bash
uv run python main.py
```

This runs the complete recursive generation pipeline:
1.  **Generate**: Creates initial questions using `google/flan-t5-large`.
2.  **Evaluate**: Scores questions using GriceWise metrics.
3.  **Cluster**: Separates high-quality vs. low-quality results.
4.  **Augment**: Updates the prompt with the best examples found so far.
5.  **Regenerate**: Retries low-quality questions with the improved prompt.
6.  **Repeat**: Runs for up to 5 iterations.

### Interactive REPL
```bash
uv run python repl.py
```

The REPL provides an interactive interface where you can:
- Enter seed questions to generate follow-ups
- View evaluation scores in real-time
- Use commands like `/help`, `/examples`, `/batch`
- Save results to JSON files

### API Usage
```python
from bfqg_generator import BFGQuestionGenerator
from gricewise_evaluator import GriceWiseEvaluator

# Generate questions (uses flan-t5-large by default)
generator = BFGQuestionGenerator()
followups = generator.generate_followups("How do I adjust the volume?")

# Evaluate questions
evaluator = GriceWiseEvaluator()
evaluation = evaluator.evaluate_question_set("How do I adjust the volume?", followups)

print(followups)  # {'level_2': '...', 'level_3': '...', ...}
print(evaluation)  # {'level_2': {'logical_consistency': 0.8, ...}, ...}
```

## Bloom's Taxonomy Levels

The system generates questions at 5 cognitive levels:

1. **Level 1: Remember** (Seed questions - not generated by system)
2. **Level 2: Understand** - Explain ideas and concepts
3. **Level 3: Apply** - Use information in new situations
4. **Level 4: Analyze** - Break down into components and relationships
5. **Level 5: Evaluate** - Make judgments based on criteria
6. **Level 6: Create** - Generate new solutions and perspectives

## GriceWise Evaluation Metrics

Each question is evaluated on four dimensions:

- **Logical Consistency (Quality)**: How well the question follows from conversation context (NLI-based / RoBERTa).
- **Informativeness (Quantity)**: Amount of new information provided (Conditional Entropy / GPT-2).
- **Relevance (Relation)**: Relatedness to the conversation topic (Embedding Similarity / MiniLM).
- **Clarity (Manner)**: Ease of understanding, calculated using **Average Dependency Distance (ADD)** via `spaCy` dependency parsing.

## Models Used

- **Question Generation**: `google/flan-t5-large` (780M params) - Upgraded from base for better instruction following.
- **Logical Consistency**: `textattack/roberta-base-MNLI`
- **Relevance**: `sentence-transformers/all-MiniLM-L6-v2`
- **Informativeness**: `gpt2`
- **Clarity**: `en_core_web_sm` (spaCy)

## Citation

If you use this implementation, please cite the original paper:

```bibtex
@inproceedings{yadav2025recall,
  title={From Recall to Creation: Generating Follow-Up Questions Using Bloom's Taxonomy and Grice's Maxims},
  author={Archana Yadav and Harshvivek Kashid and Pushpak Bhattacharyya and Medchalimi Sruthi and B JayaPrakash and Chintalapalli Raja Kullayappa and Mandala Jagadeesh Reddy},
  booktitle={Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 6: Industry Track)},
  pages={1322--1338},
  year={2025}
}
```

## License

This implementation is for academic and research purposes following the original paper's intent.
